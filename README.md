# Project Summary
Generate formal grammars in [GBNF format](https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md) for specific SQLite databases for use with text-to-sql applications with [llama.cpp](https://github.com/ggerganov/llama.cpp)

# Motivation
I want to do more RAG-type things with local data, but sometimes the data is widely varied and structured, and doesn't lend itself well towards pure semantic embeddings. Woudln't it be nice if our RAGs could retrieve local data intelligently? Enter, (text-to-SQL models)[https://blog.langchain.dev/llms-and-sql/]!

## Drawbacks of Text-to-SQL
Text-to-SQL is great (in theory), but there are a couple of sticking points that make it still difficult:

* Hallucinations are still a big problem. Providing the full database schema as part of the prompt can help, but this is not a perfect solution, and LLMs will still suggest invalid tables, columns, functions, and syntax [from time to time](https://www.chatdb.ai/post/naturalsql-vs-sqlcoder-for-text-to-sql#sqlcoder-(failed-%E2%9D%8C)). A [standard practice](https://patterns.app/blog/2023-01-18-crunchbot-sql-analyst-gpt?ref=blog.langchain.dev) is to run the query as-returned by the LLM, look for errors, and if there are errors, feed them back into the LLM (along with the original prompt and generated query) to get the LLM to attempt to fix its own bug. This is cool, but it would be nice if we could avoid this step as much as possible.

* Prompt injection and database safety. Presumably you are querying your database with a user that only has read-only access, *right*? Even so, accidents do happen, and it would be nice to limit the queries generable by the LLM to be SELECT statements-only. But when nesting queries and chaining them together with semicolons and whatnot, it can be difficult to ensure that a little Bobby Tables isn't sneaking into our queries maliciously.

## GBNF can mitigate both of these drawbacks

In late 2023, llama.cpp added a [fantastic feature](https://buduroiu.com/blog/llm-grammars-gbnf/) where the tokens generated by the LLM can be constrained to only choose amongst tokens that are valid as-defined by a formal grammar specification file. The system simply declines to consider any tokens that don't meet the specification file, which is a very speedy and efficient way of weeding out invalid generations -- you never generate them in the first place!

[Example GBNF files are provided](https://github.com/ggerganov/llama.cpp/tree/master/grammars) for things like [JSON])(https://github.com/ggerganov/llama.cpp/blob/master/grammars/json.gbnf), [chess moves](https://github.com/ggerganov/llama.cpp/blob/master/grammars/chess.gbnf), [c programs](https://github.com/ggerganov/llama.cpp/blob/master/grammars/chess.gbnf), [etc.](https://github.com/ggerganov/llama.cpp/blob/master/grammars/arithmetic.gbnf) Super cool!

But can we use this for our purposes? Yes, we can!

**By generating a GBNF specification for SQL queries, we can ensure that all queries generated by the LLM are syntactically correct.**

Further, by adapting this generalized SQL grammar to our specific SQLite database, **we can restrict the tables and columns accessed to those that are defined in our database**. This should reduce the problem of hallucinated tables and columns in our generated queries.


## Try it out!

`sqlite_select.gbnf` can be used out-of-the-box with zero modification to improve the quality of your LLM-generated SQL statements.

If you want to restrict your generated SQL to your specific database, you can run sqlite2gbnf.py, point it at your local .sqlite file, and it will auto-populate an amended version of sqlite_select.gbnf with information specific to your database schema.

This is obviously intended to work with local models that can do text-to-SQL tasks. Some candidates one might consider are:

* [NaturalSQL 6.7B](https://huggingface.co/cfahlgren1/NaturalSQL-6.7B-v0)
* [SQLCoder 7B](https://huggingface.co/defog/sqlcoder-7b)

Though as the field of interest in text-to-SQL models grows, this list should continue to grow.